import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.utils.setup import set_hf_mirrors
import json
from datasets import load_dataset

# 1. è®¾ç½®é•œåƒ
set_hf_mirrors()

def convert_to_bio(data, label_map):
    """
    å°† CMeEE çš„ span æ ¼å¼è½¬æ¢ä¸º BERT éœ€è¦çš„ BIO æ ¼å¼
    ç­–ç•¥ï¼šå¤„ç†åµŒå¥—å®ä½“æ—¶ï¼Œä¼˜å…ˆä¿ç•™æœ€é•¿çš„å®ä½“ (Longest Match)
    """
    formatted_data = []
    
    for item in data:
        text = item['text']
        entities = item.get('entities', [])
        
        # åˆå§‹åŒ–æ ‡ç­¾ï¼Œå…¨æ˜¯ 'O'
        labels = ['O'] * len(text)
        
        # æŒ‰å®ä½“é•¿åº¦é™åºæ’åˆ—ï¼Œä¼˜å…ˆå¤„ç†é•¿å®ä½“ï¼Œé¿å…åµŒå¥—å†²çª
        entities.sort(key=lambda x: x['end_idx'] - x['start_idx'], reverse=True)
        
        # è®°å½•å·²è¢«æ ‡è®°çš„ä½ç½®æ©ç 
        mask = [False] * len(text)
        
        for entity in entities:
            start = entity['start_idx']
            end = entity['end_idx']
            e_type = entity['type']
            
            # æ˜ å°„æ ‡ç­¾ (å¦‚ dis -> disease)
            # å¦‚æœä¸åœ¨æˆ‘ä»¬éœ€è¦çš„åˆ—è¡¨é‡Œï¼Œå°±è·³è¿‡
            if e_type not in label_map:
                continue
                
            mapped_type = label_map[e_type]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å ï¼ˆç®€åŒ–å¤„ç†ï¼šå¦‚æœæœ‰é‡å åˆ™è·³è¿‡çŸ­çš„ï¼‰
            if any(mask[start:end]):
                continue
                
            # æ ‡è®° BIO
            labels[start] = f"B-{mapped_type}"
            for i in range(start + 1, end):
                labels[i] = f"I-{mapped_type}"
                
            # æ›´æ–°æ©ç 
            for i in range(start, end):
                mask[i] = True
                
        formatted_data.append({
            "tokens": list(text), # æŒ‰å­—åˆ†è¯
            "ner_tags": labels
        })
    
    return formatted_data

def main():
    print("ğŸš€ æ­£åœ¨ä¸‹è½½ CMeEE-V2 æ•°æ®é›†...")
    # åŠ è½½æ•°æ®é›† (è‡ªåŠ¨ä½¿ç”¨ cache)
    dataset = load_dataset("Aunderline/CMeEE-V2", trust_remote_code=True)
    
    # å®šä¹‰æˆ‘ä»¬è¦æå–çš„æ ‡ç­¾æ˜ å°„
    # CMeEEåŸå§‹æ ‡ç­¾: dis(ç–¾ç—…), sym(ç—‡çŠ¶), dru(è¯ç‰©), pro(æ“ä½œ), equ(è®¾å¤‡), ite(æ£€æŸ¥)
    # æ˜ å°„åˆ°ä½ çš„ä½œä¸šéœ€æ±‚
    label_map = {
        "dis": "disease",
        "sym": "symptom",
        "dru": "drug",
        "pro": "check", # åŒ»ç–—ç¨‹åº/æ‰‹æœ¯ -> æ£€æŸ¥
        "ite": "check", # æ£€æŸ¥é¡¹ç›® -> æ£€æŸ¥
        # "equ": "drug", # è®¾å¤‡å¯é€‰ï¼Œæš‚æ—¶å¿½ç•¥
        # "bod": "body"  # èº«ä½“éƒ¨ä½ï¼Œä½ çš„ä½œä¸šå¥½åƒæ²¡è¦æ±‚
    }
    
    output_dir = "data/training_data"
    os.makedirs(output_dir, exist_ok=True)
    
    for split in ['train', 'test']: # CMeEE-V2 çš„ validation å…¶å®æ˜¯ dev
        print(f"æ­£åœ¨å¤„ç† {split} é›†...")
        # æ³¨æ„ï¼šhf dataset çš„ split åå­—å¯èƒ½å« 'train', 'test', 'validation'
        ds_split = 'validation' if split == 'test' else 'train'
        if ds_split not in dataset:
            print(f"è·³è¿‡ {ds_split} (ä¸å­˜åœ¨)")
            continue
            
        processed_data = convert_to_bio(dataset[ds_split], label_map)
        
        output_file = os.path.join(output_dir, f"{split}.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            for line in processed_data:
                json.dump(line, f, ensure_ascii=False)
                f.write('\n')
        
        print(f"âœ… å·²ä¿å­˜ {len(processed_data)} æ¡æ•°æ®åˆ° {output_file}")

if __name__ == "__main__":
    main()